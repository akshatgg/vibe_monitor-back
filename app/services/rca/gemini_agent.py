"""
RCA Agent Service using LangChain with Gemini LLM (supports multimodal inputs: text + images)

Updated to use capability-based tool filtering:
- Tools are selected based on workspace integrations
- Only healthy integrations contribute tools
- Uses IntegrationCapabilityResolver and AgentExecutorBuilder
"""

import base64
import logging
import re
import io
import httpx
from typing import Dict, Any, Optional, List
from urllib.parse import urlparse
from PIL import Image
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.config import settings
from .prompts import RCA_SYSTEM_PROMPT
from .capabilities import IntegrationCapabilityResolver
from .builder import AgentExecutorBuilder

logger = logging.getLogger(__name__)


class GeminiRCAAgentService:
    """
    Service for Root Cause Analysis using AI agent with Gemini (supports images).

    Updated to use capability-based tool filtering:
    - Resolves workspace integrations to capabilities
    - Only loads tools for available, healthy integrations
    - Uses AgentExecutorBuilder for clean construction
    """

    def __init__(self):
        """Initialize the RCA agent with Gemini LLM (shared across all requests)"""
        self.llm = None
        self.prompt = None
        self.capability_resolver = IntegrationCapabilityResolver(only_healthy=True)
        self._initialize_llm()

    def _initialize_llm(self):
        """Initialize the shared LLM and prompt template"""
        try:
            # Initialize Gemini LLM (stateless, can be shared)
            if not settings.GEMINI_API_KEY:
                raise ValueError("GEMINI_API_KEY not configured in environment")

            self.llm = ChatGoogleGenerativeAI(
                model=settings.GEMINI_LLM_MODEL,
                google_api_key=settings.GEMINI_API_KEY,
                temperature=settings.RCA_AGENT_TEMPERATURE,
                max_output_tokens=settings.RCA_AGENT_MAX_TOKENS,
            )
            logger.info(f"Using {settings.GEMINI_LLM_MODEL} for image analysis")

            # Create chat prompt template with system message, service mapping, and thread history
            self.prompt = ChatPromptTemplate.from_messages([
                ("system", RCA_SYSTEM_PROMPT + "\n\n## ðŸ“‹ SERVICEâ†’REPOSITORY MAPPING\n\n{service_mapping_text}\n\n{thread_history_text}"),
                ("human", "{input}"),
                ("placeholder", "{agent_scratchpad}"),
            ])

            logger.info("Gemini RCA Agent LLM initialized successfully")

        except Exception as e:
            logger.error(f"Failed to initialize Gemini RCA agent LLM: {e}")
            raise

    async def _create_agent_executor_for_workspace(
        self,
        workspace_id: str,
        db: AsyncSession,
        service_mapping: Optional[Dict[str, str]] = None,
        thread_history: Optional[str] = None,
    ):
        """
        Create a workspace-specific agent executor with capability-filtered tools.

        This method:
        1. Resolves workspace integrations to capabilities
        2. Filters tools based on available capabilities
        3. Binds workspace_id to selected tools
        4. Creates the agent executor

        Args:
            workspace_id: The workspace ID
            db: Database session for querying integrations
            service_mapping: Optional serviceâ†’repo mapping
            thread_history: Optional thread history

        Returns:
            AgentExecutor configured with capability-filtered tools
        """
        # Resolve capabilities from workspace integrations
        execution_context = await self.capability_resolver.resolve(
            workspace_id=workspace_id,
            db=db,
            service_mapping=service_mapping or {},
            thread_history=thread_history,
        )

        logger.info(
            f"Resolved capabilities for workspace {workspace_id}: "
            f"{[c.value for c in execution_context.capabilities]}"
        )
        logger.info(
            f"Active integrations: {list(execution_context.integrations.keys())}"
        )

        # Build agent executor with filtered tools
        builder = AgentExecutorBuilder(self.llm, self.prompt)
        executor = builder.with_context(execution_context).build()

        logger.info(
            f"Created Gemini agent executor for workspace {workspace_id} "
            f"with {len(executor.tools)} tools (capability-filtered)"
        )

        return executor

    async def _download_slack_images(
        self, files: List[Dict[str, Any]], access_token: str
    ) -> List[Dict[str, Any]]:
        """
        Download images from Slack URLs.

        Args:
            files: List of file objects from Slack event
            access_token: Slack bot access token for authentication

        Returns:
            List of downloaded image data with metadata
        """
        downloaded_images = []

        async with httpx.AsyncClient() as client:
            for file_obj in files:
                # Only process images
                mimetype = file_obj.get("mimetype", "")
                if not mimetype.startswith("image/"):
                    logger.info(f"Skipping non-image file: {file_obj.get('name')} ({mimetype})")
                    continue

                # Use url_private_download for direct download
                url_download = file_obj.get("url_private_download") or file_obj.get("url_private")
                if not url_download:
                    logger.warning(f"No download URL for file: {file_obj.get('name')}")
                    continue

                try:
                    # Download image with Slack auth
                    # IMPORTANT: Don't auto-follow redirects - httpx drops auth headers on cross-domain redirects
                    # We need to manually follow redirects while preserving the Authorization header
                    max_redirects = settings.RCA_SLACK_IMAGE_MAX_REDIRECTS
                    current_url = url_download

                    for redirect_count in range(max_redirects):
                        response = await client.get(
                            current_url,
                            headers={"Authorization": f"Bearer {access_token}"},
                            timeout=settings.RCA_SLACK_IMAGE_DOWNLOAD_TIMEOUT,
                            follow_redirects=False,  # Manual redirect handling to preserve auth
                        )

                        # If not a redirect, we got the final response
                        if response.status_code not in (301, 302, 303, 307, 308):
                            response.raise_for_status()
                            break

                        # Get redirect location and follow it with auth header
                        redirect_url = response.headers.get("location")
                        if not redirect_url:
                            raise Exception("Redirect response missing Location header")

                        # Parse redirect URL to validate domain
                        parsed = urlparse(redirect_url)

                        # only follow redirects to files.slack.com, not the slack login or workspace url, we need an image hrere.
                        if parsed.netloc and not parsed.netloc.startswith("files.slack.com"):
                            logger.error(
                                f"Rejecting redirect to non-files domain: {parsed.netloc}. "
                                f"This typically indicates an authentication issue. "
                                f"Slack workspace URLs return HTML login pages, not images."
                            )
                            raise Exception(
                                f"Invalid redirect to {parsed.netloc} - expected files.slack.com. "
                                f"This may indicate an expired or invalid access token."
                            )

                        current_url = redirect_url

                        # Sanitize URL to prevent token exposure in logs
                        safe_url = f"{parsed.scheme}://{parsed.netloc}{parsed.path}"
                        logger.info(f"Following redirect ({redirect_count + 1}/{max_redirects}): {safe_url}")
                    else:
                        raise Exception(f"Too many redirects (>{max_redirects}) while downloading {file_obj.get('name')}")

                    # Debug: Check what we actually downloaded
                    content_type = response.headers.get("content-type", "unknown")
                    first_bytes = response.content[:100] if len(response.content) >= 100 else response.content

                    # Validate we got an image, not HTML
                    if content_type.startswith("text/html"):
                        logger.error(
                            f"Received HTML instead of image for {file_obj.get('name')}. "
                            f"Content-Type: {content_type}, First bytes: {first_bytes[:50]!r}"
                        )
                        raise Exception(
                            f"Failed to download {file_obj.get('name')}: received HTML page instead of image. "
                            f"This may indicate an authentication issue or invalid URL."
                        )

                    logger.info(
                        f"Downloaded {file_obj.get('name')}: "
                        f"{len(response.content)} bytes, "
                        f"Content-Type: {content_type}, "
                        f"First bytes: {first_bytes[:50]!r}"
                    )

                    downloaded_images.append({
                        "name": file_obj.get("name", "image"),
                        "mimetype": mimetype,
                        "data": response.content,
                        "size": len(response.content),
                    })

                    logger.info(f"Downloaded image: {file_obj.get('name')} ({len(response.content)} bytes)")

                except Exception as e:
                    logger.error(f"Failed to download image {file_obj.get('name')}: {e}")

        return downloaded_images

    async def analyze(
        self,
        user_query: str,
        context: Optional[Dict[str, Any]] = None,
        callbacks: Optional[list] = None,
        db: Optional[AsyncSession] = None,
    ) -> Dict[str, Any]:
        """
        Perform root cause analysis for the given user query (supports images)

        Args:
            user_query: User's question or issue description (e.g., "Why is my xyz service slow?")
            context: Optional context from Slack (user_id, channel_id, workspace_id, files, etc.)
            callbacks: Optional list of callback handlers (e.g., for Slack progress updates)
            db: Database session for querying integrations (required for capability resolution)

        Returns:
            Dictionary containing:
                - output: The RCA analysis text
                - intermediate_steps: List of reasoning steps taken
                - success: Whether analysis completed successfully
                - error: Error message if failed
        """
        try:
            # Extract workspace_id from context (REQUIRED - no default)
            workspace_id = (context or {}).get("workspace_id")

            if not workspace_id:
                error_msg = "workspace_id is required in context for RCA analysis"
                logger.error(error_msg)
                return {
                    "output": None,
                    "intermediate_steps": [],
                    "success": False,
                    "error": error_msg,
                }

            if not db:
                error_msg = "db session is required for capability-based tool resolution"
                logger.error(error_msg)
                return {
                    "output": None,
                    "intermediate_steps": [],
                    "success": False,
                    "error": error_msg,
                }

            logger.info(
                f"Starting Gemini RCA analysis for query: '{user_query}' (workspace: {workspace_id})"
            )

            # Extract serviceâ†’repo mapping from context
            service_repo_mapping = (context or {}).get("service_repo_mapping", {})

            # Format the mapping for the prompt
            if service_repo_mapping:
                mapping_lines = [f"- Service `{service}` â†’ Repository `{repo}`"
                                for service, repo in service_repo_mapping.items()]
                service_mapping_text = "\n".join(mapping_lines)
                logger.info(f"Injecting serviceâ†’repo mapping with {len(service_repo_mapping)} entries")
            else:
                service_mapping_text = "(No services discovered - workspace may have no repositories)"
                logger.warning("No serviceâ†’repo mapping provided in context")

            # Extract and format thread history from context
            thread_history = (context or {}).get("thread_history", [])

            if thread_history:
                logger.info(f"Formatting thread history with {len(thread_history)} messages")

                # Format thread messages as conversation history
                history_lines = ["## ðŸ§µ CONVERSATION HISTORY", ""]
                history_lines.append("This is a follow-up question in an existing thread. Here's the previous conversation:")
                history_lines.append("")

                for msg in thread_history:
                    user_id = msg.get("user", "unknown")
                    text = msg.get("text", "")
                    bot_id = msg.get("bot_id")

                    # Strip bot mentions from message text (e.g., <@U12345678>)
                    clean_text = re.sub(settings.SLACK_USER_MENTION_PATTERN, "", text).strip()

                    # Identify if message is from bot or user
                    if bot_id:
                        history_lines.append(f"**Assistant**: {clean_text}")
                    else:
                        history_lines.append(f"**User ({user_id})**: {clean_text}")
                    history_lines.append("")

                thread_history_text = "\n".join(history_lines)
                logger.info("Thread history formatted and ready for injection")
            else:
                thread_history_text = ""
                logger.info("No thread history to format")

            # Create workspace-specific agent executor with capability-filtered tools
            agent_executor = await self._create_agent_executor_for_workspace(
                workspace_id=workspace_id,
                db=db,
                service_mapping=service_repo_mapping,
                thread_history=thread_history_text,
            )

            # Check if there are images in the context
            files = (context or {}).get("files", [])
            images = []

            if files:
                logger.info(f"Detected {len(files)} files in message, processing images...")

                # Get Slack access token to download images
                team_id = (context or {}).get("team_id")
                if team_id:
                    from app.slack.service import slack_event_service
                    from app.utils.token_processor import token_processor

                    slack_installation = await slack_event_service.get_installation(team_id)
                    if slack_installation and slack_installation.access_token:
                        try:
                            access_token = token_processor.decrypt(slack_installation.access_token)
                            images = await self._download_slack_images(files, access_token)
                            logger.info(f"Downloaded {len(images)} images for Gemini processing")
                        except Exception as e:
                            logger.error(f"Failed to decrypt Slack access token for team {team_id}: {e}")
                            logger.warning("Proceeding with text-only analysis due to token decryption failure")
                            # Continue without images rather than failing the entire job
                    else:
                        logger.warning(f"No Slack installation or access token found for team {team_id}")

            # Prepare input for the agent
            # If images are present, we need to use multimodal message format
            if images:
                logger.info(f"Processing query with {len(images)} images using Gemini multimodal")

                # For LangChain with multimodal input, we need to bypass the agent
                # and directly call the LLM with HumanMessage containing images
                # since AgentExecutor doesn't support multimodal messages natively

                # We'll call the LLM directly with image content first to get visual analysis
                from langchain_core.messages import HumanMessage

                # Create multimodal content with text and images
                # Images must be base64-encoded per LangChain Gemini docs
                content_parts = [{"type": "text", "text": user_query}]

                for img in images:
                    try:
                        # Validate image can be opened (ensures it's a valid image)
                        with Image.open(io.BytesIO(img['data'])) as pil_image:
                            logger.info(
                                f"Validated {img['name']} as valid image "
                                f"(size: {pil_image.size}, mode: {pil_image.mode}, format: {pil_image.format})"
                            )

                        # Encode image to base64 for Gemini
                        encoded = self._encode_base64(img['data'])

                        # Format per LangChain docs: nested object with "url" key
                        # https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/retrieval-augmented-generation/multimodal_rag_langchain.ipynb
                        content_parts.append({
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:{img['mimetype']};base64,{encoded}"
                            }
                        })
                        logger.info(f"Encoded {img['name']} to base64 ({len(encoded)} chars)")
                    except Exception as e:
                        logger.error(f"Failed to process {img['name']}: {e}")
                        # Skip corrupted images rather than failing entire request
                        continue

                # Create HumanMessage with multimodal content
                multimodal_message = HumanMessage(content=content_parts)

                # Notify user that images are being processed (send to Slack via callback)
                if callbacks:
                    from app.services.rca.callbacks import SlackProgressCallback
                    for callback in callbacks:
                        if isinstance(callback, SlackProgressCallback):
                            await callback.send_image_processing_notification(len(images))
                            break

                # First, get image analysis from Gemini
                try:

                    logger.info("Sending multimodal message to Gemini for image analysis...")
                    image_analysis_response = await self.llm.ainvoke([multimodal_message])
                    image_analysis = image_analysis_response.content
                    logger.info(f"Gemini image analysis completed: {len(image_analysis)} chars")
                except Exception as e:
                    logger.error(f"Failed to analyze images with Gemini: {e}")
                    image_analysis = f"[Image analysis failed: {str(e)}]"

                # Now append the image analysis to the user query for the agent
                enhanced_query = (
                    f"{user_query}\n\n"
                    f"**Visual Analysis from {len(images)} attached image(s):**\n"
                    f"{image_analysis}\n\n"
                    f"Please use the above visual analysis along with your tools to provide a comprehensive RCA."
                )

                agent_input = {
                    "input": enhanced_query,
                    "service_mapping_text": service_mapping_text,
                    "thread_history_text": thread_history_text,
                }

            else:
                # Standard text-only input
                agent_input = {
                    "input": user_query,
                    "service_mapping_text": service_mapping_text,
                    "thread_history_text": thread_history_text,
                }

            # Execute the agent asynchronously with callbacks
            if callbacks:
                result = await agent_executor.ainvoke(agent_input, config={"callbacks": callbacks})
            else:
                result = await agent_executor.ainvoke(agent_input)

            logger.info(
                f"Gemini RCA analysis completed successfully for workspace: {workspace_id}"
            )

            return {
                "output": result.get(
                    "output", "Analysis completed but no output generated."
                ),
                "intermediate_steps": result.get("intermediate_steps", []),
                "success": True,
                "error": None,
            }

        except Exception as e:
            logger.error(f"Error during Gemini RCA analysis: {e}", exc_info=True)
            return {
                "output": None,
                "intermediate_steps": [],
                "success": False,
                "error": f"RCA analysis failed: {str(e)}",
            }

    @staticmethod
    def _encode_base64(data: bytes) -> str:
        """Encode bytes to base64 string"""
        return base64.b64encode(data).decode('utf-8')

    async def analyze_with_retry(
        self,
        user_query: str,
        context: Optional[Dict[str, Any]] = None,
        max_retries: int = 2,
        callbacks: Optional[list] = None,
        db: Optional[AsyncSession] = None,
    ) -> Dict[str, Any]:
        """
        Perform RCA analysis with automatic retry on failure

        Args:
            user_query: User's question
            context: Optional context
            max_retries: Maximum number of retry attempts
            callbacks: Optional callback handlers
            db: Database session for querying integrations (required)

        Returns:
            Analysis result dictionary
        """
        for attempt in range(max_retries + 1):
            try:
                result = await self.analyze(
                    user_query, context, callbacks=callbacks, db=db
                )

                if result["success"]:
                    return result

                # If analysis didn't succeed but didn't error, retry
                logger.warning(
                    f"Gemini analysis attempt {attempt + 1} did not succeed, retrying..."
                )

            except Exception as e:
                logger.error(f"Gemini attempt {attempt + 1} failed: {e}")

                if attempt == max_retries:
                    return {
                        "output": None,
                        "intermediate_steps": [],
                        "success": False,
                        "error": f"RCA failed after {max_retries + 1} attempts: {str(e)}",
                    }

        # Should not reach here, but handle edge case
        return {
            "output": None,
            "intermediate_steps": [],
            "success": False,
            "error": "RCA analysis failed for unknown reasons",
        }


# Singleton instance
gemini_rca_agent_service = GeminiRCAAgentService()
